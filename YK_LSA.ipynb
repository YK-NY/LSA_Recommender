{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse.csr as csr\n",
    "import scipy.sparse as sparse\n",
    "from sklearn.base import clone\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = pickle.load( open( \"raw_text_dataset.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " # raw text format:\n",
    "# (X_train_raw, y_train_raw, X_test_raw, y_test)\n",
    "\n",
    "global X_train_raw, X_test_raw\n",
    "X_train_raw = raw_text[0]\n",
    "y_train_labels = raw_text[1] \n",
    "X_test_raw = raw_text[2]\n",
    "y_test_labels = raw_text[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4743"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train docs: 4743 Number of test docs: 4858 Labels in training set: 4743\n",
      "\n",
      "Example train labels: [['cocoa', 'el-salvador', 'usa', 'uruguay'], ['usa'], ['usa'], ['usa', 'brazil'], ['grain', 'wheat', 'corn', 'barley', 'oat', 'sorghum', 'usa'], ['veg-oil', 'linseed', 'lin-oil', 'soy-oil', 'sun-oil', 'soybean', 'oilseed', 'corn', 'sunseed', 'grain', 'sorghum', 'wheat', 'argentina'], ['usa'], ['usa'], ['earn', 'usa'], ['acq', 'usa'], ['earn', 'usa'], ['earn', 'acq', 'usa'], ['earn', 'usa'], ['earn', 'usa'], ['usa']]\n"
     ]
    }
   ],
   "source": [
    "print('Number of train docs:', len(X_train_raw), 'Number of test docs:', len(X_test_raw),'Labels in training set:', len(y_train_labels))\n",
    "print('\\nExample train labels:', y_train_labels[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create instance of TfifdVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5, \n",
    "                             max_features=10000,\n",
    "                             min_df=2, \n",
    "                             stop_words='english',\n",
    "                             norm='l2', \n",
    "                             use_idf=True,\n",
    "                            #     token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b'\n",
    "                            token_pattern = '(?u)\\\\b[a-zA-Z]\\\\w+\\\\b'\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vectorizer from training data\n",
    "global X_train_tfidf\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4743, 10000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4743x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 217725 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature names from the training set\n",
    "X_train_features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function doc2vec that takes a document/string and a vectorizer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def doc2vec(doc_str,vectorizer):\n",
    "       \n",
    "    # use the vectorizer object to transform the input string\n",
    "    doc_vec = vectorizer.transform(doc_str) # returns a sparse matrix\n",
    "    print(\"Input doc:\", doc_str)\n",
    "    print(doc_vec.shape)\n",
    "            \n",
    "    # get features for the dataset.\n",
    "    doc_features = vectorizer.get_feature_names()\n",
    "    \n",
    "    # get feature count in the *INPUT* document\n",
    "    c_vectorizer_input = CountVectorizer()\n",
    "    fc_input = c_vectorizer_input.fit_transform(doc_str)  # train using the input document\n",
    "    print(\"feature names in input doc:\", c_vectorizer_input.vocabulary_)\n",
    "    print(\"feature count in input doc:\", fc_input.toarray())\n",
    "\n",
    "    # get feature count in the training dataset; apply transform on the input string\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    fc_data = count_vectorizer.fit_transform(X_train_raw) # train using the corpus training data set\n",
    "    \n",
    "    fc_data_vec = count_vectorizer.transform(doc_str) # transform the input string\n",
    "           \n",
    "    print(\"training data feature count:\",fc_data_vec.toarray())\n",
    "    #print(\"training data feature count:\",fc_data_vec.toarray().nonzero())\n",
    "        \n",
    "    # returning the vector for input document, features and the feature count for the training data\n",
    "    return doc_vec.toarray(), doc_features, fc_data_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"The cocoa cadabra\"\n",
    "doc2 = \"AAPL SE\"\n",
    "doc3 = \"bullish stocks\"\n",
    "doc4 = \"I walked through a random forest and earned a high premium\"\n",
    "\n",
    "all_docs = [doc1,doc2,doc3,doc4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call doc2vec function on each of the strings above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input doc: ['The cocoa cadabra']\n",
      "(1, 10000)\n",
      "feature names in input doc: {'the': 2, 'cocoa': 1, 'cadabra': 0}\n",
      "feature count in input doc: [[1 1 1]]\n",
      "training data feature count: [[0 0 0 ... 0 0 0]]\n",
      "Input doc: ['AAPL SE']\n",
      "(1, 10000)\n",
      "feature names in input doc: {'se': 1, 'aapl': 0}\n",
      "feature count in input doc: [[1 1]]\n",
      "training data feature count: [[0 0 0 ... 0 0 0]]\n",
      "Input doc: ['bullish stocks']\n",
      "(1, 10000)\n",
      "feature names in input doc: {'stocks': 1, 'bullish': 0}\n",
      "feature count in input doc: [[1 1]]\n",
      "training data feature count: [[0 0 0 ... 0 0 0]]\n",
      "Input doc: ['I walked through a random forest and earned a high premium']\n",
      "(1, 10000)\n",
      "feature names in input doc: {'premium': 4, 'high': 3, 'forest': 2, 'through': 6, 'and': 0, 'walked': 7, 'earned': 1, 'random': 5}\n",
      "feature count in input doc: [[1 1 1 1 1 1 1 1]]\n",
      "training data feature count: [[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vec_1, features_1, f_count_1 = doc2vec([doc1],vectorizer)\n",
    "vec_2, features_2, f_count_2 = doc2vec([doc2],vectorizer)\n",
    "vec_3, features_3, f_count_3 = doc2vec([doc3],vectorizer)\n",
    "vec_4, features_4, f_count_4 = doc2vec([doc4],vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LSA for feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fewer features and project the tfidf vectors previously obtained onto these principal components.\n",
    "svd = TruncatedSVD(\n",
    "    n_components=200,\n",
    "    random_state=42,\n",
    "    algorithm='arpack'\n",
    ")\n",
    "\n",
    "lsa = make_pipeline(\n",
    "    svd, \n",
    "    #Normalizer(copy=False)\n",
    ")\n",
    "\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Explained variance of the SVD step: 40%\n"
     ]
    }
   ],
   "source": [
    "# explained variance with and without the Normalizer is the same, at 40%\n",
    "\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"  Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))\n",
    "\n",
    "# Now apply the transformations to the test data as well.\n",
    "\n",
    "X_test_tfidf = vectorizer.transform(X_test_raw)\n",
    "X_test_lsa = lsa.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to project document vectors on the lsa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to transform docs using lsa model\n",
    "def doc2vec_lsa(vec,lsa):\n",
    "    return lsa.transform(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_vec_1 = doc2vec_lsa(vec_1,lsa)\n",
    "lsa_vec_2 = doc2vec_lsa(vec_2,lsa)\n",
    "lsa_vec_3 = doc2vec_lsa(vec_3,lsa)\n",
    "lsa_vec_4 = doc2vec_lsa(vec_4,lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend(vec,X_model,X_corpus):\n",
    "    \n",
    "    #computes similarity score between the input document and the input model\n",
    "    sim_vec = cosine_similarity(vec,X_model)\n",
    "    \n",
    "    # flatten the ndarray\n",
    "    doc_vec = sim_vec.ravel()\n",
    "    #print(\"Similarity scores:\",doc_vec)\n",
    "    print(doc_vec.shape)\n",
    "    \n",
    "    #sim_top10    \n",
    "    sim_top10 = -np.sort(-doc_vec,axis=None)[:10]\n",
    "    print(\"Top 10 similarity scores:\", sim_top10)\n",
    "    \n",
    "    #idx_top10\n",
    "    idx = np.argsort(doc_vec,axis=-1)\n",
    "    idx_top10 = np.flip(idx)[:10]\n",
    "    print(\"Indices of the top 10 similarity scores:\",idx_top10,\"\\n\")\n",
    "        \n",
    "    #X_top10\n",
    "    X_top10 = []\n",
    "    for i in idx_top10:\n",
    "        #print(\"\\n\", X_corpus[i])\n",
    "        X_top10.append(X_corpus[i])\n",
    "        \n",
    "    return doc_vec, sim_top10, idx_top10, X_top10\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using document vectors for doc1, doc2, doc3 and doc4 for the tfidf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4743,)\n",
      "Top 10 similarity scores: [0.42235728 0.42040369 0.35255483 0.35085335 0.2988182  0.14068797\n",
      " 0.11826212 0.1143153  0.10724859 0.05619974]\n",
      "Indices of the top 10 similarity scores: [3009 2974    0  266 3917 3092 2318 4232 1720 4322] \n",
      "\n",
      "(4743,)\n",
      "Top 10 similarity scores: [0.20399735 0.20365975 0.19772875 0.17447117 0.1672799  0.14959382\n",
      " 0.13094691 0.11369229 0.10175478 0.04976086]\n",
      "Indices of the top 10 similarity scores: [ 358 2555  376 2480  473  693 2539 2961  980 3326] \n",
      "\n",
      "(4743,)\n",
      "Top 10 similarity scores: [0.30381139 0.30381139 0.29963665 0.25871352 0.25514106 0.20313366\n",
      " 0.19031362 0.17583325 0.1702555  0.16728479]\n",
      "Indices of the top 10 similarity scores: [4467 4417 1542 1687 3751  246 3747 1202 1190 1682] \n",
      "\n",
      "(4743,)\n",
      "Top 10 similarity scores: [0.20513221 0.2010637  0.10954859 0.10767873 0.10503232 0.09503946\n",
      " 0.09346369 0.08627354 0.08562531 0.08477512]\n",
      "Indices of the top 10 similarity scores: [3157 3144 4014 1669  472  467 3638 4678  651 3254] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# passing the X_tfidf sparse matrix\n",
    "\n",
    "doc_vec_1, sim_top10_1, idx_top10_1, X_top10_1 = recommend(vec_1,X_train_tfidf,X_train_raw)\n",
    "doc_vec_2, sim_top10_2, idx_top10_2, X_top10_2 = recommend(vec_2,X_train_tfidf,X_train_raw)\n",
    "doc_vec_3, sim_top10_3, idx_top10_3, X_top10_3 = recommend(vec_3,X_train_tfidf,X_train_raw)\n",
    "doc_vec_4, sim_top10_4, idx_top10_4, X_top10_4 = recommend(vec_4,X_train_tfidf,X_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using document vectors for doc1, doc2, doc3 and doc4 for the lsa model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4743,)\n",
      "Top 10 similarity scores: [0.66299725 0.63583877 0.58200046 0.51773392 0.49465865 0.47773937\n",
      " 0.46553139 0.44976251 0.44355088 0.43288301]\n",
      "Indices of the top 10 similarity scores: [3009 2974  266 3833  894  220 3917 1741 3339 2867] \n",
      "\n",
      "(4743,)\n",
      "Top 10 similarity scores: [0.86037122 0.80394306 0.74667568 0.74475129 0.74081637 0.69813517\n",
      " 0.69508071 0.68335518 0.65656429 0.63659858]\n",
      "Indices of the top 10 similarity scores: [ 473  693 1354  358  376 2818 2961 4254 3580  980] \n",
      "\n",
      "(4743,)\n",
      "Top 10 similarity scores: [0.75442851 0.75425952 0.74885696 0.73217583 0.72090926 0.64055845\n",
      " 0.60239534 0.50100177 0.45536005 0.43358076]\n",
      "Indices of the top 10 similarity scores: [3751 1190 1687 1682 3747 1202 1542  670  663 2991] \n",
      "\n",
      "(4743,)\n",
      "Top 10 similarity scores: [0.43183902 0.42397246 0.41647472 0.41646787 0.40471379 0.40289744\n",
      " 0.39757218 0.39311349 0.39311349 0.39298254]\n",
      "Indices of the top 10 similarity scores: [3418 4642 4659 3482 3489 4040 1324 4458 4424 4081] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# passing the X_train_lsa matrix\n",
    "\n",
    "lsa_doc_vec_1, lsa_sim_top10_1, lsa_idx_top10_1, lsa_X_top10_1 = recommend(lsa_vec_1,X_train_lsa,X_train_raw)\n",
    "lsa_doc_vec_2, lsa_sim_top10_2, lsa_idx_top10_2, lsa_X_top10_2 = recommend(lsa_vec_2,X_train_lsa,X_train_raw)\n",
    "lsa_doc_vec_3, lsa_sim_top10_3, lsa_idx_top10_3, lsa_X_top10_3 = recommend(lsa_vec_3,X_train_lsa,X_train_raw)\n",
    "lsa_doc_vec_4, lsa_sim_top10_4, lsa_idx_top10_4, lsa_X_top10_4 = recommend(lsa_vec_4,X_train_lsa,X_train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCULSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity scores obtained by using the LSA model (with fewer features) is far superior than those obtained by using \n",
    "the tfidf matrix with large number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds19",
   "language": "python",
   "name": "ds19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
